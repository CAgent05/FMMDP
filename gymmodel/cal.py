import torch
from stable_baselines3 import PPO
import numpy as np

def count_parameters(model):
    """è®¡ç®—PyTorchæ¨¡å‹çš„å‚æ•°æ•°é‡"""
    return sum(p.numel() for p in model.parameters() if p.requires_grad)

def get_model_size_mb(model):
    """è®¡ç®—æ¨¡å‹å¤§å°(MB)"""
    total_params = count_parameters(model)
    size_bytes = total_params * 4  # FP32
    size_mb = size_bytes / (1024 * 1024)
    return total_params, size_mb

def analyze_ppo_model_correct(model_path):
    """æ­£ç¡®çš„PPOæ¨¡å‹å‚æ•°åˆ†æ"""
    model = PPO.load(model_path)
    
    print("=== ä¿®æ­£åçš„PPOæ¨¡å‹åˆ†æ ===")
    print(f"Policyç±»å‹: {type(model.policy).__name__}")
    
    # æ–¹æ³•1: æ•´ä¸ªpolicyçš„æ€»å‚æ•°ï¼ˆè¿™æ˜¯æœ€å‡†ç¡®çš„ï¼‰
    total_params, total_size_mb = get_model_size_mb(model.policy)
    print(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
    print(f"æ€»å‚æ•°æ•°é‡: {total_params:,}")
    print(f"æ€»æ¨¡å‹å¤§å°: {total_size_mb:.2f} MB")
    
    # æ–¹æ³•2: åˆ†æä¸»è¦ç»„ä»¶
    print(f"\nğŸ” ä¸»è¦ç»„ä»¶åˆ†æ:")
    print(f"{'ç»„ä»¶åç§°':25} | {'å‚æ•°æ•°é‡':>10} | {'å¤§å°(MB)':>8}")
    print("-" * 55)
    
    # æ£€æŸ¥å…±äº«ç‰¹å¾æå–å™¨çš„å†…éƒ¨ç»“æ„
    if hasattr(model.policy, 'mlp_extractor'):
        extractor = model.policy.mlp_extractor
        
        # åˆ†æç‰¹å¾æå–å™¨çš„å„ä¸ªéƒ¨åˆ†
        if hasattr(extractor, 'shared_net'):
            shared_params, shared_size = get_model_size_mb(extractor.shared_net)
            print(f"{'å…±äº«ç½‘ç»œ':25} | {shared_params:>8,} | {shared_size:>6.2f}")
        
        if hasattr(extractor, 'policy_net'):
            policy_params, policy_size = get_model_size_mb(extractor.policy_net)
            print(f"{'ç­–ç•¥ç‰¹å¾ç½‘ç»œ':25} | {policy_params:>8,} | {policy_size:>6.2f}")
            
        if hasattr(extractor, 'value_net'):
            value_params, value_size = get_model_size_mb(extractor.value_net)
            print(f"{'ä»·å€¼ç‰¹å¾ç½‘ç»œ':25} | {value_params:>8,} | {value_size:>6.2f}")
    
    # è¾“å‡ºå±‚
    if hasattr(model.policy, 'action_net'):
        action_params, action_size = get_model_size_mb(model.policy.action_net)
        print(f"{'åŠ¨ä½œè¾“å‡ºå±‚':25} | {action_params:>8,} | {action_size:>6.2f}")
    
    if hasattr(model.policy, 'value_net'):
        value_out_params, value_out_size = get_model_size_mb(model.policy.value_net)
        print(f"{'ä»·å€¼è¾“å‡ºå±‚':25} | {value_out_params:>8,} | {value_out_size:>6.2f}")
    
    print("-" * 55)
    
    # æ–¹æ³•3: æŒ‰å±‚è¯¦ç»†åˆ†æ
    print(f"\nğŸ—ï¸ è¯¦ç»†å±‚çº§åˆ†æ:")
    print(f"{'å±‚åç§°':40} | {'å‚æ•°æ•°é‡':>10} | {'å¤§å°(MB)':>8}")
    print("-" * 70)
    
    layer_count = 0
    for name, module in model.policy.named_modules():
        if len(list(module.children())) == 0:  # å¶å­èŠ‚ç‚¹
            params = sum(p.numel() for p in module.parameters())
            if params > 0:
                size_mb = params * 4 / (1024 * 1024)
                layer_count += 1
                if layer_count <= 20:  # åªæ˜¾ç¤ºå‰20å±‚
                    print(f"{name[:40]:40} | {params:>8,} | {size_mb:>6.2f}")
    
    if layer_count > 20:
        print(f"... (è¿˜æœ‰ {layer_count-20} å±‚)")
    
    print("-" * 70)
    print(f"{'æ€»è®¡éªŒè¯':40} | {total_params:>8,} | {total_size_mb:>6.2f}")
    
    # æ–¹æ³•4: ç½‘ç»œç»“æ„å¯è§†åŒ–
    print(f"\nğŸ¯ ç½‘ç»œç»“æ„:")
    print(model.policy)
    
    return {
        'total_parameters': total_params,
        'total_size_mb': total_size_mb,
        'policy_type': type(model.policy).__name__
    }

# ä½¿ç”¨ä¿®æ­£åçš„æ–¹æ³•
model_analysis = analyze_ppo_model_correct("/home/cy/PaperWork/FMMDP/gymmodel/CarRacing.zip")